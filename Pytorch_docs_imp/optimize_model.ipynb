{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Model Parameters\n",
    "\n",
    "### Now that we have a model and data itâ€™s time to train, validate and test our model by optimizing its parameters on our data. Training a model is an iterative process; in each iteration the model makes a guess about the output, calculates the error in its guess (loss), collects the derivatives of the error with respect to its parameters (as we saw in the previous section), and optimizes these parameters using gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_data,batch_size=32)\n",
    "test_dataloader=DataLoader(test_data,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        logits=self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model=NeuralNetwork()    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "learning_rate=1e-3\n",
    "batch_size=32\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop \n",
    "\n",
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    size=len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred,y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch%100==0:\n",
    "            loss,current=loss.item(),batch*batch_size+len(X)\n",
    "            print(f\"Loss->{loss} current->{current} size->{size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing loop (valdiation)\n",
    "\n",
    "def test(dataloader,model,loss_fn):\n",
    "    model.eval()\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches=len(dataloader)\n",
    "    test_loss,correct=0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            pred=model(X)\n",
    "            test_loss+=loss_fn(pred,y)\n",
    "            correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss=test_loss/num_batches\n",
    "    correct=correct/size\n",
    "    \n",
    "    print(f\"test accuracy is {100*correct}% and average loss is {test_loss}\")        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0---------------------------\n",
      "Loss->2.292773962020874 current->32 size->60000\n",
      "Loss->2.2895328998565674 current->3232 size->60000\n",
      "Loss->2.2935073375701904 current->6432 size->60000\n",
      "Loss->2.3061904907226562 current->9632 size->60000\n",
      "Loss->2.3014676570892334 current->12832 size->60000\n",
      "Loss->2.2843220233917236 current->16032 size->60000\n",
      "Loss->2.2888054847717285 current->19232 size->60000\n",
      "Loss->2.2803986072540283 current->22432 size->60000\n",
      "Loss->2.288588762283325 current->25632 size->60000\n",
      "Loss->2.263746738433838 current->28832 size->60000\n",
      "Loss->2.2708828449249268 current->32032 size->60000\n",
      "Loss->2.2709312438964844 current->35232 size->60000\n",
      "Loss->2.2794458866119385 current->38432 size->60000\n",
      "Loss->2.2631986141204834 current->41632 size->60000\n",
      "Loss->2.261119842529297 current->44832 size->60000\n",
      "Loss->2.257246971130371 current->48032 size->60000\n",
      "Loss->2.2695815563201904 current->51232 size->60000\n",
      "Loss->2.250166654586792 current->54432 size->60000\n",
      "Loss->2.234530448913574 current->57632 size->60000\n",
      "test accuracy is 18.82% and average loss is 2.242152452468872\n",
      "epoch 1---------------------------\n",
      "Loss->2.2288646697998047 current->32 size->60000\n",
      "Loss->2.24971342086792 current->3232 size->60000\n",
      "Loss->2.23885440826416 current->6432 size->60000\n",
      "Loss->2.2432615756988525 current->9632 size->60000\n",
      "Loss->2.2336976528167725 current->12832 size->60000\n",
      "Loss->2.2190616130828857 current->16032 size->60000\n",
      "Loss->2.187321424484253 current->19232 size->60000\n",
      "Loss->2.181737184524536 current->22432 size->60000\n",
      "Loss->2.197049140930176 current->25632 size->60000\n",
      "Loss->2.154125452041626 current->28832 size->60000\n",
      "Loss->2.150038242340088 current->32032 size->60000\n",
      "Loss->2.1251089572906494 current->35232 size->60000\n",
      "Loss->2.1954493522644043 current->38432 size->60000\n",
      "Loss->2.1291708946228027 current->41632 size->60000\n",
      "Loss->2.1275100708007812 current->44832 size->60000\n",
      "Loss->2.1207871437072754 current->48032 size->60000\n",
      "Loss->2.139174222946167 current->51232 size->60000\n",
      "Loss->2.095130443572998 current->54432 size->60000\n",
      "Loss->2.052273988723755 current->57632 size->60000\n",
      "test accuracy is 34.955000000000005% and average loss is 2.0422780513763428\n",
      "epoch 2---------------------------\n",
      "Loss->2.0245819091796875 current->32 size->60000\n",
      "Loss->2.064664840698242 current->3232 size->60000\n",
      "Loss->2.033093214035034 current->6432 size->60000\n",
      "Loss->2.0090830326080322 current->9632 size->60000\n",
      "Loss->1.9711040258407593 current->12832 size->60000\n",
      "Loss->1.9908618927001953 current->16032 size->60000\n",
      "Loss->1.8097717761993408 current->19232 size->60000\n",
      "Loss->1.8277995586395264 current->22432 size->60000\n",
      "Loss->1.866438388824463 current->25632 size->60000\n",
      "Loss->1.7940281629562378 current->28832 size->60000\n",
      "Loss->1.726651668548584 current->32032 size->60000\n",
      "Loss->1.6587309837341309 current->35232 size->60000\n",
      "Loss->1.8231136798858643 current->38432 size->60000\n",
      "Loss->1.6624505519866943 current->41632 size->60000\n",
      "Loss->1.6403034925460815 current->44832 size->60000\n",
      "Loss->1.6359540224075317 current->48032 size->60000\n",
      "Loss->1.6433767080307007 current->51232 size->60000\n",
      "Loss->1.6406018733978271 current->54432 size->60000\n",
      "Loss->1.5087674856185913 current->57632 size->60000\n",
      "test accuracy is 52.73% and average loss is 1.5160268545150757\n",
      "epoch 3---------------------------\n",
      "Loss->1.4922819137573242 current->32 size->60000\n",
      "Loss->1.5044399499893188 current->3232 size->60000\n",
      "Loss->1.502502679824829 current->6432 size->60000\n",
      "Loss->1.474141001701355 current->9632 size->60000\n",
      "Loss->1.3851146697998047 current->12832 size->60000\n",
      "Loss->1.5342292785644531 current->16032 size->60000\n",
      "Loss->1.2599117755889893 current->19232 size->60000\n",
      "Loss->1.3018651008605957 current->22432 size->60000\n",
      "Loss->1.3677457571029663 current->25632 size->60000\n",
      "Loss->1.3430825471878052 current->28832 size->60000\n",
      "Loss->1.213927984237671 current->32032 size->60000\n",
      "Loss->1.157226800918579 current->35232 size->60000\n",
      "Loss->1.3929587602615356 current->38432 size->60000\n",
      "Loss->1.2208805084228516 current->41632 size->60000\n",
      "Loss->1.2321574687957764 current->44832 size->60000\n",
      "Loss->1.1481664180755615 current->48032 size->60000\n",
      "Loss->1.1993356943130493 current->51232 size->60000\n",
      "Loss->1.3668416738510132 current->54432 size->60000\n",
      "Loss->1.0858306884765625 current->57632 size->60000\n",
      "test accuracy is 61.266666666666666% and average loss is 1.1496392488479614\n",
      "epoch 4---------------------------\n",
      "Loss->1.1270545721054077 current->32 size->60000\n",
      "Loss->1.145155906677246 current->3232 size->60000\n",
      "Loss->1.1722863912582397 current->6432 size->60000\n",
      "Loss->1.2546645402908325 current->9632 size->60000\n",
      "Loss->1.0378055572509766 current->12832 size->60000\n",
      "Loss->1.2462985515594482 current->16032 size->60000\n",
      "Loss->0.9344472885131836 current->19232 size->60000\n",
      "Loss->0.9847293496131897 current->22432 size->60000\n",
      "Loss->1.0433645248413086 current->25632 size->60000\n",
      "Loss->1.1477985382080078 current->28832 size->60000\n",
      "Loss->0.9711139798164368 current->32032 size->60000\n",
      "Loss->0.9025388360023499 current->35232 size->60000\n",
      "Loss->1.213304042816162 current->38432 size->60000\n",
      "Loss->1.0209373235702515 current->41632 size->60000\n",
      "Loss->1.0488123893737793 current->44832 size->60000\n",
      "Loss->0.9207019805908203 current->48032 size->60000\n",
      "Loss->0.9734864830970764 current->51232 size->60000\n",
      "Loss->1.2570343017578125 current->54432 size->60000\n",
      "Loss->0.8866497278213501 current->57632 size->60000\n",
      "test accuracy is 65.44666666666666% and average loss is 0.9702598452568054\n",
      "epoch 5---------------------------\n",
      "Loss->0.9183925986289978 current->32 size->60000\n",
      "Loss->0.9718945622444153 current->3232 size->60000\n",
      "Loss->1.0156193971633911 current->6432 size->60000\n",
      "Loss->1.1472303867340088 current->9632 size->60000\n",
      "Loss->0.8548146486282349 current->12832 size->60000\n",
      "Loss->1.1016188859939575 current->16032 size->60000\n",
      "Loss->0.7624836564064026 current->19232 size->60000\n",
      "Loss->0.8186285495758057 current->22432 size->60000\n",
      "Loss->0.8785009384155273 current->25632 size->60000\n",
      "Loss->1.0691859722137451 current->28832 size->60000\n",
      "Loss->0.8301466107368469 current->32032 size->60000\n",
      "Loss->0.7805915474891663 current->35232 size->60000\n",
      "Loss->1.136853814125061 current->38432 size->60000\n",
      "Loss->0.9331135153770447 current->41632 size->60000\n",
      "Loss->0.9512628316879272 current->44832 size->60000\n",
      "Loss->0.7950062155723572 current->48032 size->60000\n",
      "Loss->0.8352287411689758 current->51232 size->60000\n",
      "Loss->1.1700857877731323 current->54432 size->60000\n",
      "Loss->0.7798668742179871 current->57632 size->60000\n",
      "test accuracy is 68.74166666666667% and average loss is 0.8646141290664673\n",
      "epoch 6---------------------------\n",
      "Loss->0.7794272899627686 current->32 size->60000\n",
      "Loss->0.8697531819343567 current->3232 size->60000\n",
      "Loss->0.8976086974143982 current->6432 size->60000\n",
      "Loss->1.0370643138885498 current->9632 size->60000\n",
      "Loss->0.7512887120246887 current->12832 size->60000\n",
      "Loss->1.0239827632904053 current->16032 size->60000\n",
      "Loss->0.6588112115859985 current->19232 size->60000\n",
      "Loss->0.7049310803413391 current->22432 size->60000\n",
      "Loss->0.7822706699371338 current->25632 size->60000\n",
      "Loss->1.0174388885498047 current->28832 size->60000\n",
      "Loss->0.73134845495224 current->32032 size->60000\n",
      "Loss->0.7116310000419617 current->35232 size->60000\n",
      "Loss->1.0827062129974365 current->38432 size->60000\n",
      "Loss->0.8891195058822632 current->41632 size->60000\n",
      "Loss->0.8860017657279968 current->44832 size->60000\n",
      "Loss->0.7082024812698364 current->48032 size->60000\n",
      "Loss->0.7455874681472778 current->51232 size->60000\n",
      "Loss->1.0779222249984741 current->54432 size->60000\n",
      "Loss->0.7188696265220642 current->57632 size->60000\n",
      "test accuracy is 70.96000000000001% and average loss is 0.7919011116027832\n",
      "epoch 7---------------------------\n",
      "Loss->0.6858701109886169 current->32 size->60000\n",
      "Loss->0.810802698135376 current->3232 size->60000\n",
      "Loss->0.7948215007781982 current->6432 size->60000\n",
      "Loss->0.9205008745193481 current->9632 size->60000\n",
      "Loss->0.6859698295593262 current->12832 size->60000\n",
      "Loss->0.9788320064544678 current->16032 size->60000\n",
      "Loss->0.5963069796562195 current->19232 size->60000\n",
      "Loss->0.6202784180641174 current->22432 size->60000\n",
      "Loss->0.7170160412788391 current->25632 size->60000\n",
      "Loss->0.9762115478515625 current->28832 size->60000\n",
      "Loss->0.6765362024307251 current->32032 size->60000\n",
      "Loss->0.6694869995117188 current->35232 size->60000\n",
      "Loss->1.0313701629638672 current->38432 size->60000\n",
      "Loss->0.8720370531082153 current->41632 size->60000\n",
      "Loss->0.8381801843643188 current->44832 size->60000\n",
      "Loss->0.656539261341095 current->48032 size->60000\n",
      "Loss->0.6904075741767883 current->51232 size->60000\n",
      "Loss->0.9970811605453491 current->54432 size->60000\n",
      "Loss->0.6866750717163086 current->57632 size->60000\n",
      "test accuracy is 72.77833333333334% and average loss is 0.7424534559249878\n",
      "epoch 8---------------------------\n",
      "Loss->0.6249001026153564 current->32 size->60000\n",
      "Loss->0.7754504084587097 current->3232 size->60000\n",
      "Loss->0.7141556143760681 current->6432 size->60000\n",
      "Loss->0.8253360986709595 current->9632 size->60000\n",
      "Loss->0.6381831765174866 current->12832 size->60000\n",
      "Loss->0.9528554677963257 current->16032 size->60000\n",
      "Loss->0.5619540810585022 current->19232 size->60000\n",
      "Loss->0.5584774613380432 current->22432 size->60000\n",
      "Loss->0.6700026988983154 current->25632 size->60000\n",
      "Loss->0.9406325817108154 current->28832 size->60000\n",
      "Loss->0.6528441309928894 current->32032 size->60000\n",
      "Loss->0.6418255567550659 current->35232 size->60000\n",
      "Loss->0.9812876582145691 current->38432 size->60000\n",
      "Loss->0.8646353483200073 current->41632 size->60000\n",
      "Loss->0.7972832918167114 current->44832 size->60000\n",
      "Loss->0.624098539352417 current->48032 size->60000\n",
      "Loss->0.6527600288391113 current->51232 size->60000\n",
      "Loss->0.930593729019165 current->54432 size->60000\n",
      "Loss->0.668502151966095 current->57632 size->60000\n",
      "test accuracy is 74.26166666666667% and average loss is 0.705638587474823\n",
      "epoch 9---------------------------\n",
      "Loss->0.5816895365715027 current->32 size->60000\n",
      "Loss->0.7484419941902161 current->3232 size->60000\n",
      "Loss->0.6570718884468079 current->6432 size->60000\n",
      "Loss->0.7583217620849609 current->9632 size->60000\n",
      "Loss->0.5996750593185425 current->12832 size->60000\n",
      "Loss->0.9329930543899536 current->16032 size->60000\n",
      "Loss->0.5395393371582031 current->19232 size->60000\n",
      "Loss->0.5090945363044739 current->22432 size->60000\n",
      "Loss->0.635238766670227 current->25632 size->60000\n",
      "Loss->0.9077076315879822 current->28832 size->60000\n",
      "Loss->0.6427459716796875 current->32032 size->60000\n",
      "Loss->0.6195223331451416 current->35232 size->60000\n",
      "Loss->0.9349340200424194 current->38432 size->60000\n",
      "Loss->0.8583083152770996 current->41632 size->60000\n",
      "Loss->0.759860634803772 current->44832 size->60000\n",
      "Loss->0.5995007157325745 current->48032 size->60000\n",
      "Loss->0.6219393014907837 current->51232 size->60000\n",
      "Loss->0.8758289217948914 current->54432 size->60000\n",
      "Loss->0.6559252738952637 current->57632 size->60000\n",
      "test accuracy is 75.47166666666666% and average loss is 0.67542964220047\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"epoch {t}---------------------------\")\n",
    "    train(train_dataloader,model,loss_fn,optimizer)\n",
    "    test(train_dataloader,model,loss_fn)\n",
    "print(\"Done!!!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
